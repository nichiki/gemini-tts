import streamlit as st
import pandas as pd
import os
import io
import zipfile
import tempfile
from google import genai
from google.genai import types
import wave
from dotenv import load_dotenv
from datetime import datetime
import time

# Load environment variables
load_dotenv()

# Initialize Gemini client
@st.cache_resource
def init_client():
    # Try Streamlit secrets first, then environment variables
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        api_key = os.environ.get("GEMINI_API_KEY")

    return genai.Client(
        api_key=api_key,
        http_options=types.HttpOptions(
            client_args={"timeout": 60.0}  # ç§’
        )
    )

# Wave file creation function
def create_wave_file(pcm_data, channels=1, rate=24000, sample_width=2):
    """Create a wave file in memory from PCM data"""
    buffer = io.BytesIO()
    with wave.open(buffer, "wb") as wf:
        wf.setnchannels(channels)
        wf.setsampwidth(sample_width)
        wf.setframerate(rate)
        wf.writeframes(pcm_data)
    buffer.seek(0)
    return buffer

# TTS generation function
def generate_tts(client, text, voice="Zephyr", instruction="", temperature=1.0, model="gemini-2.5-pro-preview-tts"):
    """Generate TTS for given text with specified parameters and instructions"""
    try:
        # Combine instruction and text if instruction is provided
        if instruction:
            contents = f"""Instructions: {instruction}

Please read the following lines according to the instructions above:
"{text}" """
        else:
            contents = text
        
        print(f"  ğŸ”„ Calling API with temperature={temperature}, voice={voice}")
        
        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=types.GenerateContentConfig(
                temperature=temperature,
                response_modalities=["AUDIO"],
                speech_config=types.SpeechConfig(
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                            voice_name=voice,
                        )
                    )
                ),
            )
        )
        
        if not response or not response.candidates:
            print(f"  âš ï¸ Empty response from API")
            return None
            
        pcm_data = response.candidates[0].content.parts[0].inline_data.data
        print(f"  âœ… Generated audio ({len(pcm_data)} bytes)")
        return pcm_data
    except Exception as e:
        import traceback
        error_msg = f"ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}"
        st.error(error_msg)
        print(f"TTS Generation Error: {error_msg}")  # Console logging
        return None

# Available voices with descriptions
VOICE_INFO = {
    # å¥³æ€§å£°ï¼ˆFemale voicesï¼‰
    "Zephyr": "å¥³æ€§ãƒ»è½ã¡ç€ã„ãŸå£°",
    "Kore": "å¥³æ€§ãƒ»æ˜ã‚‹ã„å£°",
    "Aoede": "å¥³æ€§ãƒ»å„ªã—ã„å£°",
    "Callirhoe": "å¥³æ€§ãƒ»ä¸Šå“ãªå£°",
    "Autonoe": "å¥³æ€§ãƒ»å…ƒæ°—ãªå£°",
    "Despina": "å¥³æ€§ãƒ»æŸ”ã‚‰ã‹ã„å£°",
    "Erinome": "å¥³æ€§ãƒ»çŸ¥çš„ãªå£°",
    "Laomedeia": "å¥³æ€§ãƒ»ç©ã‚„ã‹ãªå£°",
    "Schedar": "å¥³æ€§ãƒ»ã¯ãã¯ãã—ãŸå£°",
    "Pulcherrima": "å¥³æ€§ãƒ»è¯ã‚„ã‹ãªå£°",
    "Vindemiatrix": "å¥³æ€§ãƒ»æ·±ã¿ã®ã‚ã‚‹å£°",
    
    # ç”·æ€§å£°ï¼ˆMale voicesï¼‰
    "Puck": "ç”·æ€§ãƒ»è‹¥ã€…ã—ã„å£°",
    "Charon": "ç”·æ€§ãƒ»è½ã¡ç€ã„ãŸå£°",
    "Fenrir": "ç”·æ€§ãƒ»åŠ›å¼·ã„å£°",
    "Leda": "ç”·æ€§ãƒ»å„ªã—ã„å£°",
    "Orus": "ç”·æ€§ãƒ»æ¸‹ã„å£°",
    "Enceladus": "ç”·æ€§ãƒ»é‡åšãªå£°",
    "Iapetus": "ç”·æ€§ãƒ»çŸ¥çš„ãªå£°",
    "Umbriel": "ç”·æ€§ãƒ»ç©ã‚„ã‹ãªå£°",
    "Algieba": "ç”·æ€§ãƒ»æ˜ç­ãªå£°",
    "Algenib": "ç”·æ€§ãƒ»ã¯ã£ãã‚Šã—ãŸå£°",
    "Rasalgethi": "ç”·æ€§ãƒ»æ·±ã„å£°",
    "Achernar": "ç”·æ€§ãƒ»ã‚¯ãƒªã‚¢ãªå£°",
    "Alnilam": "ç”·æ€§ãƒ»æ¸©ã‹ã„å£°",
    "Gacrux": "ç”·æ€§ãƒ»ã—ã£ã‹ã‚Šã—ãŸå£°",
    "Achird": "ç”·æ€§ãƒ»è¦ªã—ã¿ã‚„ã™ã„å£°",
    "Zubenelgenubi": "ç”·æ€§ãƒ»ç‹¬ç‰¹ãªå£°",
    "Sadachbia": "ç”·æ€§ãƒ»ã•ã‚ã‚„ã‹ãªå£°",
    "Sadaltager": "ç”·æ€§ãƒ»å°è±¡çš„ãªå£°",
    "Sulafar": "ç”·æ€§ãƒ»å€‹æ€§çš„ãªå£°"
}

VOICE_OPTIONS = list(VOICE_INFO.keys())

# Simple authentication
def check_password():
    """Returns `True` if the user had the correct password."""

    def password_entered():
        """Checks whether a password entered by the user is correct."""
        # Get password from secrets or environment
        try:
            correct_password = st.secrets["APP_PASSWORD"]
        except:
            correct_password = os.environ.get("APP_PASSWORD", "demo123")  # Default for development

        if st.session_state["password"] == correct_password:
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # Don't store password
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        # First run, show input for password
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            type="password",
            on_change=password_entered,
            key="password"
        )
        return False
    elif not st.session_state["password_correct"]:
        # Password not correct, show input + error
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            type="password",
            on_change=password_entered,
            key="password"
        )
        st.error("ğŸ˜• ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        return False
    else:
        # Password correct
        return True

# Streamlit App
def main():
    st.set_page_config(
        page_title="Gemini TTS ä¸€æ‹¬éŸ³å£°ç”Ÿæˆ",
        page_icon="ğŸ™ï¸",
        layout="wide"
    )

    st.title("ğŸ™ï¸ Gemini TTS ä¸€æ‹¬éŸ³å£°ç”Ÿæˆãƒ„ãƒ¼ãƒ«")

    # Check authentication
    if not check_password():
        st.stop()

    st.markdown("å°æœ¬CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€è¤‡æ•°ã®éŸ³å£°ã‚’ä¸€æ‹¬ç”Ÿæˆã—ã¾ã™ã€‚")

    # Initialize session state
    if 'generated_files' not in st.session_state:
        st.session_state.generated_files = []
    
    # Main content area - Initialize default values early
    default_voice = "Zephyr"  # Default voice
    default_instruction = ""
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“„ å°æœ¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        # CSV template download
        st.markdown("### CSVãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")
        template_data = {
            'text': [
                'ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚æœ¬æ—¥ã¯æ™´å¤©ãªã‚Šã€‚',
                'ç¶šã„ã¦ã€ãŠçŸ¥ã‚‰ã›ã§ã™ã€‚',
                'ã”æ¸…è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚'
            ],
            'voice': ['Zephyr', 'Kore', 'Zephyr'],
            'filename': ['greeting', 'announcement', 'closing'],
            'instruction': [
                'æ˜ã‚‹ãå…ƒæ°—ãªå£°ã§',
                'ã¯ã£ãã‚Šã¨èãå–ã‚Šã‚„ã™ã',
                'ã‚†ã£ãã‚Šã¨ä¸å¯§ã«'
            ]
        }
        
        template_df = pd.DataFrame(template_data)
        # UTF-8 with BOM for Excel compatibility
        csv_template = template_df.to_csv(index=False, encoding='utf-8-sig')
        
        st.download_button(
            label="ğŸ“¥ CSVãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_template.encode('utf-8-sig'),
            file_name="tts_template.csv",
            mime="text/csv"
        )
        
        # File uploader
        uploaded_file = st.file_uploader(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['csv'],
            help="textåˆ—ã¯å¿…é ˆã§ã™ã€‚voice, filename, instructionåˆ—ã¯ä»»æ„ã§ã™ã€‚"
        )
        
        if uploaded_file is not None:
            try:
                # Read CSV - try utf-8-sig first (for Excel), then fallback to utf-8
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                except:
                    uploaded_file.seek(0)  # Reset file pointer
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                
                # Validate required column
                if 'text' not in df.columns:
                    st.error("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã«'text'åˆ—ãŒå¿…è¦ã§ã™ã€‚")
                else:
                    # Ensure columns exist (but keep empty values as-is)
                    if 'voice' not in df.columns:
                        df['voice'] = pd.NA
                    if 'filename' not in df.columns:
                        df['filename'] = pd.NA
                    if 'instruction' not in df.columns:
                        df['instruction'] = pd.NA
                    
                    # Display preview
                    st.success(f"âœ… {len(df)}ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                    st.dataframe(df, height=300)
                    
                    # Store in session state
                    st.session_state.df = df
                    
            except Exception as e:
                st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with col2:
        st.header("ğŸµ éŸ³å£°ç”Ÿæˆ")
        
        # Default settings section
        st.subheader("ğŸ“Š ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š")
        
        # Model selector
        model_options = [
            "gemini-2.5-flash-preview-tts",
            "gemini-2.5-pro-preview-tts"
        ]
        default_model = st.selectbox(
            "TTSãƒ¢ãƒ‡ãƒ«",
            model_options,
            index=0,  # Default to Flash
            help="Flash: é«˜é€Ÿãƒ»è»½é‡ / Pro: é«˜å“è³ªãƒ»é«˜ç²¾åº¦"
        )
        
        # Voice selector with descriptions
        voice_display_options = [f"{voice} ({desc})" for voice, desc in VOICE_INFO.items()]
        selected_voice_display = st.selectbox(
            "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©±è€…",
            voice_display_options,
            index=0,
            help="ç”Ÿæˆã™ã‚‹éŸ³å£°ã®è©±è€…ã‚’é¸æŠã—ã¾ã™ã€‚ã‚«ãƒƒã‚³å†…ã¯å£°ã®ç‰¹å¾´ã§ã™ã€‚"
        )
        # Extract voice name from display string
        default_voice = selected_voice_display.split(" (")[0]
        
        # Default instruction
        default_instruction = st.text_area(
            "å…¨ä½“ã®æ¼”æŠ€æŒ‡ç¤º",
            value="",
            height=80,
            help="ä¾‹: æ˜ã‚‹ãå…ƒæ°—ãªå£°ã§èª­ã‚€ã€ã‚†ã£ãã‚Šã¨è½ã¡ç€ã„ãŸå£°ã§èª­ã‚€ã€ãªã©",
            placeholder="å…¨ä½“ã®æ¼”æŠ€æŒ‡ç¤ºï¼ˆä»»æ„ï¼‰"
        )
        
        # Initialize default values for advanced settings
        default_temperature = 1.0
        
        # Advanced settings in expander
        with st.expander("âš™ï¸ è©³ç´°è¨­å®š", expanded=False):
            default_temperature = st.slider(
                "æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
                min_value=0.1,
                max_value=2.0,
                value=1.0,
                step=0.1,
                help="ä½ã„å€¤ã§ã‚ˆã‚Šä¸€è²«æ€§ã®ã‚ã‚‹éŸ³å£°ã€é«˜ã„å€¤ã§ã‚ˆã‚Šå¤šæ§˜ãªéŸ³å£°ãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼ˆæ¨™æº–: 1.0ï¼‰"
            )
        
        st.divider()
        
        if 'df' in st.session_state:
            df = st.session_state.df
            
            # Generation button
            if st.button("ğŸš€ éŸ³å£°ã‚’ä¸€æ‹¬ç”Ÿæˆ", type="primary", use_container_width=True):
                client = init_client()
                
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                generated_files = []
                
                # Create temporary directory
                with tempfile.TemporaryDirectory() as temp_dir:
                    for idx, row in df.iterrows():
                        # Update progress
                        progress = (idx + 1) / len(df)
                        progress_bar.progress(progress)
                        # Get display filename (handle NaN)
                        display_filename = row.get('filename')
                        if pd.isna(display_filename) or str(display_filename).strip() == '':
                            display_filename = f"audio_{idx+1:03d}"
                        status_text.text(f"ç”Ÿæˆä¸­... ({idx + 1}/{len(df)}) - {display_filename}")
                        
                        # Get actual voice that will be used
                        voice_for_log = row.get('voice')
                        if pd.isna(voice_for_log) or str(voice_for_log).strip() == '':
                            voice_for_log = default_voice
                        
                        # Debug logging
                        print(f"\nğŸ¯ Processing {idx + 1}/{len(df)}: {display_filename}")
                        print(f"   Model: {default_model}")
                        print(f"   Voice: {voice_for_log}")
                        
                        # Skip empty text
                        if pd.isna(row.get('text')) or str(row.get('text')).strip() == '':
                            st.warning(f"è¡Œ {idx + 1}: ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                            continue
                        
                        # Combine default and individual instructions
                        combined_instruction = ''
                        if default_instruction:
                            combined_instruction = default_instruction
                        
                        # Check for instruction and handle NaN
                        individual_instruction = row.get('instruction', '')
                        if pd.notna(individual_instruction) and str(individual_instruction).strip():
                            if combined_instruction:
                                combined_instruction += f"\n{individual_instruction}"
                            else:
                                combined_instruction = individual_instruction
                        
                        # Use default values when CSV values are empty/invalid
                        voice_name = row.get('voice')
                        if pd.isna(voice_name) or str(voice_name).strip() == '' or voice_name not in VOICE_OPTIONS:
                            voice_name = default_voice
                        
                        pcm_data = generate_tts(
                            client,
                            row['text'],
                            voice=voice_name,
                            instruction=combined_instruction,
                            temperature=default_temperature,
                            model=default_model
                        )
                        
                        if pcm_data:
                            # Create wave file
                            wave_buffer = create_wave_file(pcm_data)
                            # Use default filename if empty
                            file_base = row.get('filename')
                            if pd.isna(file_base) or str(file_base).strip() == '':
                                file_base = f"audio_{idx+1:03d}"
                            filename = f"{file_base}.wav"
                            
                            # Save to temp directory
                            file_path = os.path.join(temp_dir, filename)
                            with open(file_path, 'wb') as f:
                                f.write(wave_buffer.getvalue())
                            
                            generated_files.append({
                                'filename': filename,
                                'text': row['text'][:50] + '...' if len(row['text']) > 50 else row['text'],
                                'voice': voice_name,  # Use the validated voice name
                                'path': file_path,
                                'data': wave_buffer.getvalue()
                            })
                        
                        # Small delay to avoid rate limiting
                        time.sleep(1.5)
                    
                    # Complete
                    progress_bar.progress(1.0)
                    status_text.text("âœ… ç”Ÿæˆå®Œäº†ï¼")
                    
                    # Store results
                    st.session_state.generated_files = generated_files
                    
                    # Create ZIP file
                    if generated_files:
                        zip_buffer = io.BytesIO()
                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for file_info in generated_files:
                                zip_file.writestr(file_info['filename'], file_info['data'])
                        
                        zip_buffer.seek(0)
                        st.session_state.zip_data = zip_buffer.getvalue()
            
            # Display results
            if st.session_state.generated_files:
                st.header("ğŸ“¦ ç”Ÿæˆçµæœ")
                
                # Download all button
                if 'zip_data' in st.session_state:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    st.download_button(
                        label="ğŸ“¥ ã™ã¹ã¦ã®éŸ³å£°ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=st.session_state.zip_data,
                        file_name=f"tts_output_{timestamp}.zip",
                        mime="application/zip",
                        type="primary",
                        use_container_width=True
                    )
                
                # Individual file preview
                st.subheader("å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«")
                for file_info in st.session_state.generated_files:
                    with st.expander(f"ğŸ”Š {file_info['filename']}"):
                        st.text(f"ãƒ†ã‚­ã‚¹ãƒˆ: {file_info['text']}")
                        st.text(f"è©±è€…: {file_info['voice']}")
                        st.audio(file_info['data'], format='audio/wav')
                        st.download_button(
                            label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=file_info['data'],
                            file_name=file_info['filename'],
                            mime="audio/wav",
                            key=f"download_{file_info['filename']}"
                        )
        else:
            st.info("ğŸ‘ˆ ã¾ãšCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()